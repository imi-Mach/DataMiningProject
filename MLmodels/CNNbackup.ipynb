{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "The objective of this file is to provide work for the implmentation and execution of the convolutional neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Dense, Flatten, Conv1D, MaxPooling1D, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelBinarizer\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(484, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "# Hardcode which dataset for 1D CNN {Cho = 1, Iyer = 2}\n",
    "option = 2\n",
    "\n",
    "n_features = 16\n",
    "n_outputs  = 5\n",
    "\n",
    "# locate Cho data\n",
    "if(option == 1):\n",
    "    datapath = '../data/'\n",
    "    filename = 'cho.txt'\n",
    "# Locate Iyer data\n",
    "else:\n",
    "    datapath = '../data/'\n",
    "    filename = 'iyer.txt'\n",
    "    n_features = 12\n",
    "    n_outputs  = 10\n",
    "\n",
    "# Load data as a numpy array\n",
    "dataSet = np.genfromtxt(datapath+filename)\n",
    "\n",
    "# Remove -1 extraenous class from dataset\n",
    "if(option != 1):\n",
    "    dataSet = dataSet[dataSet[:,1]>-1, :]\n",
    "\n",
    "\n",
    "# Extract features from dataSet\n",
    "X = dataSet [:,2:]\n",
    "\n",
    "# Extract class labels (for hyperparamter tuning and evaluation)\n",
    "y = dataSet[:,1]\n",
    "\n",
    "# Create simple test, train split for demonstration (Tensorflow)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size=0.67, \n",
    "                                                    random_state=42)\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X = X.reshape((X.shape[0], X.shape[1],1))\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],1))\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model must be defined for Grid Search CV\n",
    "def create_model(filter_num=0, ker_size=0, dropout_r=0.0,dense=0):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=filter_num, kernel_size=ker_size, activation='relu', input_shape=(n_features, 1)))\n",
    "    model.add(Dropout(dropout_r))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense, activation='relu'))\n",
    "    model.add(Dense(n_outputs+1, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n",
      "Fitting 10 folds for each of 81 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 457 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 457 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 521 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 521 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 554 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 554 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 589 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done 589 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 661 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=-1)]: Done 661 tasks      | elapsed: 17.3min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-99e8489f6d0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-99e8489f6d0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size = 10, verbose=0)\n",
    "\n",
    "# Create range of values for Grid Search CV\n",
    "filter_num = [8, 16,32]\n",
    "ker_size    = [2, 4, 6]\n",
    "dropout_r  = [0.5,0.6,0.7]\n",
    "dense      = [20,60,120]\n",
    "\n",
    "# Generate dictionary for matching model parameters\n",
    "param_grid = dict(filter_num=filter_num, ker_size=ker_size, dropout_r=dropout_r, dense=dense)\n",
    "\n",
    "# Define the K-fold crossvalidation method\n",
    "cv_method = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Perform Hyperparameterization function GridSearchCV(...)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv_method, scoring='accuracy',verbose=10)\n",
    "\n",
    "# Extract results\n",
    "grid.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([13.64881208, 12.48634889, 12.23947093, 13.26500795, 13.56234176,\n",
      "       14.3876826 , 15.07664008, 14.57159564, 14.60995555, 13.24105809,\n",
      "       13.65430124, 14.54712236, 15.23403192, 15.26401289, 15.28186743,\n",
      "       14.04450095, 14.04808283, 14.51010077, 13.27183242, 13.61537361,\n",
      "       12.95290933, 13.75034921, 14.86689181, 15.46683431, 16.2215317 ,\n",
      "       16.15559082, 15.7871891 , 13.60152972, 13.41840022, 13.44074409,\n",
      "       13.98856981, 13.6584491 , 13.26404049, 15.36632688, 17.78952665,\n",
      "       15.79327133, 14.37996325, 14.2809938 , 13.74946322, 14.72259164,\n",
      "       16.52140989, 15.37126265, 15.24040978, 17.14210916, 18.04217799,\n",
      "       16.89437177, 14.9286025 , 16.09355967, 16.38890049, 15.45350072,\n",
      "       15.31856949, 17.0979141 , 16.54405375, 17.48659863, 13.90942688,\n",
      "       13.78001366, 13.76961832, 15.85111442, 15.70735216, 15.09014435,\n",
      "       15.67900784, 16.06034417, 15.68788519, 13.78811107, 13.9513818 ,\n",
      "       14.2116045 , 15.12751834, 14.9716588 , 15.25616887, 16.64789922,\n",
      "       16.38629234, 15.17951789, 13.80825551, 15.12057362, 14.2831948 ,\n",
      "       15.21279769, 15.42154109, 15.15433011, 17.46409926, 16.72965102,\n",
      "       14.93416355]), 'std_fit_time': array([0.64448072, 0.56252908, 0.599586  , 1.74053224, 1.0938157 ,\n",
      "       0.72299003, 0.74897823, 0.8089545 , 0.88291178, 1.01349062,\n",
      "       0.91486858, 1.34358883, 0.70312948, 1.19056094, 0.82930169,\n",
      "       0.4554778 , 0.8230562 , 0.82003252, 0.90828413, 0.60653682,\n",
      "       0.64261744, 1.21079945, 0.89906943, 0.53068748, 0.48537426,\n",
      "       0.68091561, 0.99863606, 0.97090643, 0.9184751 , 0.73049161,\n",
      "       0.4762152 , 0.56614873, 0.71266855, 0.91520248, 0.88810866,\n",
      "       1.36119142, 0.9947763 , 0.47249047, 0.61979799, 1.65629749,\n",
      "       1.37560955, 0.40376908, 0.54572242, 0.65839511, 0.6878446 ,\n",
      "       1.60538912, 1.04319965, 1.03422537, 0.52939884, 1.00128572,\n",
      "       1.04700863, 0.84059289, 0.87022102, 1.16343496, 0.90900007,\n",
      "       0.49184157, 0.52106582, 1.33587405, 0.69177851, 0.68682011,\n",
      "       0.95767809, 1.07121009, 0.83635798, 0.78162192, 0.5238286 ,\n",
      "       0.82186229, 0.82809731, 0.59178408, 0.84781679, 0.71729701,\n",
      "       0.51212336, 0.37938166, 0.86854557, 0.76173486, 0.64499052,\n",
      "       0.53693863, 0.27407179, 0.60856862, 1.28473515, 0.79315795,\n",
      "       0.99343022]), 'mean_score_time': array([0.7137228 , 0.58325708, 0.57008758, 0.57949343, 0.60022278,\n",
      "       0.6651381 , 0.6818187 , 0.7361583 , 0.66581707, 0.7315259 ,\n",
      "       0.68791344, 0.7944993 , 0.71951258, 0.72040653, 0.65508077,\n",
      "       0.59928126, 0.64488926, 0.66528361, 0.67148995, 0.64887433,\n",
      "       0.73057752, 0.64895003, 0.71542301, 0.70874703, 0.7643127 ,\n",
      "       0.71626072, 0.64307182, 0.75835032, 0.69883845, 0.64760761,\n",
      "       0.72327018, 0.68273463, 0.6606096 , 0.75003688, 0.85920422,\n",
      "       0.82835112, 0.74465568, 0.70226216, 0.69205387, 0.71102579,\n",
      "       0.82029579, 0.74405193, 0.81486771, 0.87619793, 0.81715531,\n",
      "       0.75418839, 0.79910419, 0.73510058, 0.68657365, 0.75111461,\n",
      "       0.80184402, 0.77024252, 0.82300179, 0.91281152, 0.79927275,\n",
      "       0.74027705, 0.83445385, 0.80001304, 0.75876975, 0.72332039,\n",
      "       0.82764051, 0.80976844, 0.80670762, 0.79629061, 0.83780828,\n",
      "       0.74190717, 0.76557102, 0.86805942, 0.81977148, 0.86151912,\n",
      "       0.75581048, 0.79133813, 0.77095437, 0.80779922, 0.86676831,\n",
      "       0.88113501, 0.86122189, 0.79989722, 0.8403111 , 0.93121097,\n",
      "       0.49593558]), 'std_score_time': array([0.29398144, 0.10562022, 0.22383996, 0.19833088, 0.22087018,\n",
      "       0.45920132, 0.20142625, 0.21470455, 0.18093527, 0.24433285,\n",
      "       0.34799103, 0.36460225, 0.29137441, 0.30892514, 0.2054645 ,\n",
      "       0.14826097, 0.20955559, 0.22060068, 0.20657753, 0.19649742,\n",
      "       0.27661211, 0.17523694, 0.24792961, 0.29776413, 0.32692863,\n",
      "       0.22065771, 0.11965304, 0.28811712, 0.20696712, 0.18341045,\n",
      "       0.21546964, 0.24670712, 0.20826793, 0.1934234 , 0.31798942,\n",
      "       0.2454828 , 0.22383143, 0.2108075 , 0.24858331, 0.14042387,\n",
      "       0.1041055 , 0.1509085 , 0.21678964, 0.15900352, 0.11585202,\n",
      "       0.23093773, 0.2612121 , 0.15148154, 0.17541929, 0.15210339,\n",
      "       0.1607367 , 0.19316741, 0.18886924, 0.17199584, 0.14660776,\n",
      "       0.16232209, 0.31659535, 0.19047754, 0.14691503, 0.18050391,\n",
      "       0.26626467, 0.24284857, 0.21699205, 0.28276993, 0.17530324,\n",
      "       0.11672328, 0.09646411, 0.15505892, 0.16688496, 0.17663529,\n",
      "       0.15902718, 0.2190615 , 0.16210854, 0.12862516, 0.08293848,\n",
      "       0.16049469, 0.12482209, 0.22347903, 0.07553558, 0.11590347,\n",
      "       0.29065053]), 'param_dense': masked_array(data=[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 60,\n",
      "                   60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60,\n",
      "                   60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 120,\n",
      "                   120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "                   120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "                   120, 120, 120, 120],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_dropout_r': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6,\n",
      "                   0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
      "                   0.6, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6, 0.6,\n",
      "                   0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_filter_num': masked_array(data=[8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16,\n",
      "                   32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8,\n",
      "                   16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
      "                   32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
      "                   16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
      "                   8, 16, 16, 16, 32, 32, 32],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_ker_size': masked_array(data=[2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6,\n",
      "                   2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6,\n",
      "                   2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6,\n",
      "                   2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6,\n",
      "                   2, 4, 6, 2, 4, 6, 2, 4, 6],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'dense': 20, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 6}], 'split0_test_score': array([0.76923077, 0.74358974, 0.66666667, 0.82051282, 0.76923077,\n",
      "       0.76923077, 0.74358974, 0.74358974, 0.74358974, 0.74358974,\n",
      "       0.69230769, 0.66666667, 0.71794872, 0.74358974, 0.71794872,\n",
      "       0.74358974, 0.76923077, 0.74358974, 0.66666667, 0.69230769,\n",
      "       0.69230769, 0.71794872, 0.71794872, 0.69230769, 0.71794872,\n",
      "       0.71794872, 0.71794872, 0.69230769, 0.74358974, 0.71794872,\n",
      "       0.74358974, 0.71794872, 0.74358974, 0.71794872, 0.66666667,\n",
      "       0.76923077, 0.66666667, 0.66666667, 0.71794872, 0.74358974,\n",
      "       0.71794872, 0.74358974, 0.74358974, 0.71794872, 0.74358974,\n",
      "       0.69230769, 0.69230769, 0.61538462, 0.71794872, 0.66666667,\n",
      "       0.66666667, 0.74358974, 0.69230769, 0.71794872, 0.69230769,\n",
      "       0.71794872, 0.71794872, 0.71794872, 0.71794872, 0.69230769,\n",
      "       0.74358974, 0.69230769, 0.74358974, 0.71794872, 0.71794872,\n",
      "       0.69230769, 0.74358974, 0.76923077, 0.69230769, 0.74358974,\n",
      "       0.69230769, 0.71794872, 0.66666667, 0.61538462, 0.66666667,\n",
      "       0.76923077, 0.71794872, 0.71794872, 0.69230769, 0.74358974,\n",
      "       0.71794872]), 'split1_test_score': array([0.87179487, 0.84615385, 0.71794872, 0.82051282, 0.87179487,\n",
      "       0.87179487, 0.79487179, 0.84615385, 0.87179487, 0.84615385,\n",
      "       0.87179487, 0.84615385, 0.84615385, 0.82051282, 0.87179487,\n",
      "       0.87179487, 0.84615385, 0.8974359 , 0.79487179, 0.79487179,\n",
      "       0.82051282, 0.87179487, 0.79487179, 0.84615385, 0.87179487,\n",
      "       0.8974359 , 0.87179487, 0.84615385, 0.8974359 , 0.84615385,\n",
      "       0.87179487, 0.8974359 , 0.82051282, 0.87179487, 0.87179487,\n",
      "       0.82051282, 0.84615385, 0.82051282, 0.82051282, 0.84615385,\n",
      "       0.87179487, 0.84615385, 0.82051282, 0.87179487, 0.82051282,\n",
      "       0.76923077, 0.82051282, 0.84615385, 0.87179487, 0.87179487,\n",
      "       0.8974359 , 0.87179487, 0.8974359 , 0.84615385, 0.84615385,\n",
      "       0.84615385, 0.71794872, 0.87179487, 0.84615385, 0.82051282,\n",
      "       0.84615385, 0.84615385, 0.84615385, 0.76923077, 0.8974359 ,\n",
      "       0.79487179, 0.84615385, 0.84615385, 0.82051282, 0.84615385,\n",
      "       0.76923077, 0.82051282, 0.84615385, 0.84615385, 0.8974359 ,\n",
      "       0.84615385, 0.84615385, 0.87179487, 0.84615385, 0.87179487,\n",
      "       0.87179487]), 'split2_test_score': array([0.82051282, 0.84615385, 0.82051282, 0.84615385, 0.84615385,\n",
      "       0.84615385, 0.76923077, 0.82051282, 0.84615385, 0.8974359 ,\n",
      "       0.84615385, 0.87179487, 0.84615385, 0.84615385, 0.84615385,\n",
      "       0.84615385, 0.82051282, 0.82051282, 0.8974359 , 0.82051282,\n",
      "       0.87179487, 0.87179487, 0.84615385, 0.82051282, 0.84615385,\n",
      "       0.84615385, 0.84615385, 0.79487179, 0.82051282, 0.82051282,\n",
      "       0.84615385, 0.76923077, 0.84615385, 0.82051282, 0.82051282,\n",
      "       0.79487179, 0.82051282, 0.82051282, 0.82051282, 0.82051282,\n",
      "       0.82051282, 0.87179487, 0.82051282, 0.84615385, 0.84615385,\n",
      "       0.82051282, 0.79487179, 0.79487179, 0.87179487, 0.84615385,\n",
      "       0.79487179, 0.79487179, 0.84615385, 0.84615385, 0.79487179,\n",
      "       0.79487179, 0.82051282, 0.79487179, 0.84615385, 0.82051282,\n",
      "       0.84615385, 0.82051282, 0.84615385, 0.87179487, 0.79487179,\n",
      "       0.82051282, 0.79487179, 0.82051282, 0.87179487, 0.79487179,\n",
      "       0.87179487, 0.82051282, 0.84615385, 0.79487179, 0.79487179,\n",
      "       0.84615385, 0.82051282, 0.82051282, 0.84615385, 0.74358974,\n",
      "       0.87179487]), 'split3_test_score': array([0.79487179, 0.71794872, 0.71794872, 0.76923077, 0.76923077,\n",
      "       0.84615385, 0.71794872, 0.76923077, 0.79487179, 0.76923077,\n",
      "       0.76923077, 0.71794872, 0.74358974, 0.74358974, 0.69230769,\n",
      "       0.76923077, 0.74358974, 0.76923077, 0.71794872, 0.79487179,\n",
      "       0.74358974, 0.69230769, 0.76923077, 0.71794872, 0.74358974,\n",
      "       0.79487179, 0.82051282, 0.76923077, 0.76923077, 0.74358974,\n",
      "       0.76923077, 0.74358974, 0.71794872, 0.69230769, 0.74358974,\n",
      "       0.76923077, 0.79487179, 0.74358974, 0.76923077, 0.66666667,\n",
      "       0.79487179, 0.74358974, 0.74358974, 0.74358974, 0.79487179,\n",
      "       0.71794872, 0.74358974, 0.79487179, 0.76923077, 0.74358974,\n",
      "       0.69230769, 0.71794872, 0.74358974, 0.74358974, 0.76923077,\n",
      "       0.74358974, 0.71794872, 0.74358974, 0.69230769, 0.74358974,\n",
      "       0.71794872, 0.74358974, 0.76923077, 0.74358974, 0.76923077,\n",
      "       0.74358974, 0.74358974, 0.71794872, 0.76923077, 0.76923077,\n",
      "       0.71794872, 0.76923077, 0.74358974, 0.69230769, 0.69230769,\n",
      "       0.74358974, 0.76923077, 0.71794872, 0.74358974, 0.79487179,\n",
      "       0.74358974]), 'split4_test_score': array([0.58974359, 0.64102564, 0.69230769, 0.64102564, 0.71794872,\n",
      "       0.69230769, 0.69230769, 0.69230769, 0.69230769, 0.58974359,\n",
      "       0.66666667, 0.66666667, 0.61538462, 0.66666667, 0.61538462,\n",
      "       0.66666667, 0.66666667, 0.64102564, 0.61538462, 0.66666667,\n",
      "       0.71794872, 0.61538462, 0.66666667, 0.64102564, 0.61538462,\n",
      "       0.64102564, 0.69230769, 0.66666667, 0.69230769, 0.64102564,\n",
      "       0.64102564, 0.64102564, 0.66666667, 0.64102564, 0.66666667,\n",
      "       0.66666667, 0.61538462, 0.61538462, 0.66666667, 0.69230769,\n",
      "       0.58974359, 0.64102564, 0.66666667, 0.66666667, 0.69230769,\n",
      "       0.64102564, 0.58974359, 0.64102564, 0.64102564, 0.64102564,\n",
      "       0.69230769, 0.69230769, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.64102564, 0.69230769, 0.71794872, 0.66666667, 0.66666667,\n",
      "       0.66666667, 0.66666667, 0.74358974, 0.66666667, 0.66666667,\n",
      "       0.61538462, 0.66666667, 0.61538462, 0.69230769, 0.74358974,\n",
      "       0.64102564, 0.66666667, 0.58974359, 0.64102564, 0.71794872,\n",
      "       0.69230769, 0.64102564, 0.64102564, 0.66666667, 0.61538462,\n",
      "       0.71794872]), 'split5_test_score': array([0.66666667, 0.64102564, 0.69230769, 0.71794872, 0.74358974,\n",
      "       0.69230769, 0.69230769, 0.74358974, 0.71794872, 0.66666667,\n",
      "       0.61538462, 0.66666667, 0.69230769, 0.64102564, 0.66666667,\n",
      "       0.69230769, 0.74358974, 0.74358974, 0.64102564, 0.66666667,\n",
      "       0.66666667, 0.66666667, 0.64102564, 0.64102564, 0.64102564,\n",
      "       0.69230769, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.61538462, 0.66666667, 0.74358974, 0.66666667, 0.71794872,\n",
      "       0.69230769, 0.69230769, 0.66666667, 0.64102564, 0.69230769,\n",
      "       0.71794872, 0.64102564, 0.69230769, 0.66666667, 0.76923077,\n",
      "       0.66666667, 0.66666667, 0.66666667, 0.71794872, 0.58974359,\n",
      "       0.69230769, 0.64102564, 0.71794872, 0.71794872, 0.66666667,\n",
      "       0.69230769, 0.64102564, 0.61538462, 0.66666667, 0.74358974,\n",
      "       0.61538462, 0.71794872, 0.71794872, 0.66666667, 0.66666667,\n",
      "       0.71794872, 0.71794872, 0.69230769, 0.69230769, 0.71794872,\n",
      "       0.69230769, 0.66666667, 0.66666667, 0.69230769, 0.66666667,\n",
      "       0.61538462, 0.74358974, 0.69230769, 0.69230769, 0.69230769,\n",
      "       0.74358974]), 'split6_test_score': array([0.73684211, 0.76315789, 0.76315789, 0.73684211, 0.76315789,\n",
      "       0.81578947, 0.71052632, 0.73684211, 0.81578947, 0.81578947,\n",
      "       0.84210526, 0.78947368, 0.73684211, 0.73684211, 0.78947368,\n",
      "       0.71052632, 0.84210526, 0.78947368, 0.78947368, 0.84210526,\n",
      "       0.76315789, 0.76315789, 0.78947368, 0.71052632, 0.71052632,\n",
      "       0.78947368, 0.81578947, 0.76315789, 0.78947368, 0.76315789,\n",
      "       0.68421053, 0.65789474, 0.81578947, 0.71052632, 0.71052632,\n",
      "       0.78947368, 0.68421053, 0.81578947, 0.76315789, 0.65789474,\n",
      "       0.78947368, 0.76315789, 0.71052632, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.78947368, 0.78947368, 0.76315789, 0.81578947,\n",
      "       0.78947368, 0.71052632, 0.73684211, 0.73684211, 0.65789474,\n",
      "       0.84210526, 0.78947368, 0.65789474, 0.84210526, 0.81578947,\n",
      "       0.68421053, 0.73684211, 0.78947368, 0.81578947, 0.78947368,\n",
      "       0.81578947, 0.65789474, 0.73684211, 0.78947368, 0.68421053,\n",
      "       0.71052632, 0.73684211, 0.73684211, 0.76315789, 0.81578947,\n",
      "       0.78947368, 0.81578947, 0.86842105, 0.68421053, 0.68421053,\n",
      "       0.81578947]), 'split7_test_score': array([0.68421053, 0.68421053, 0.73684211, 0.76315789, 0.78947368,\n",
      "       0.73684211, 0.71052632, 0.76315789, 0.71052632, 0.71052632,\n",
      "       0.68421053, 0.71052632, 0.71052632, 0.73684211, 0.71052632,\n",
      "       0.71052632, 0.73684211, 0.71052632, 0.71052632, 0.68421053,\n",
      "       0.71052632, 0.76315789, 0.71052632, 0.71052632, 0.71052632,\n",
      "       0.68421053, 0.76315789, 0.71052632, 0.71052632, 0.71052632,\n",
      "       0.68421053, 0.73684211, 0.71052632, 0.73684211, 0.76315789,\n",
      "       0.71052632, 0.73684211, 0.73684211, 0.71052632, 0.73684211,\n",
      "       0.76315789, 0.71052632, 0.71052632, 0.71052632, 0.71052632,\n",
      "       0.71052632, 0.73684211, 0.65789474, 0.73684211, 0.68421053,\n",
      "       0.71052632, 0.68421053, 0.76315789, 0.73684211, 0.78947368,\n",
      "       0.73684211, 0.71052632, 0.73684211, 0.68421053, 0.76315789,\n",
      "       0.71052632, 0.68421053, 0.73684211, 0.73684211, 0.71052632,\n",
      "       0.73684211, 0.73684211, 0.68421053, 0.73684211, 0.71052632,\n",
      "       0.76315789, 0.71052632, 0.71052632, 0.76315789, 0.73684211,\n",
      "       0.76315789, 0.71052632, 0.71052632, 0.71052632, 0.71052632,\n",
      "       0.65789474]), 'split8_test_score': array([0.86842105, 0.86842105, 0.84210526, 0.81578947, 0.84210526,\n",
      "       0.84210526, 0.78947368, 0.84210526, 0.81578947, 0.78947368,\n",
      "       0.78947368, 0.84210526, 0.84210526, 0.81578947, 0.84210526,\n",
      "       0.78947368, 0.86842105, 0.89473684, 0.76315789, 0.84210526,\n",
      "       0.81578947, 0.84210526, 0.84210526, 0.81578947, 0.84210526,\n",
      "       0.92105263, 0.86842105, 0.84210526, 0.86842105, 0.81578947,\n",
      "       0.81578947, 0.78947368, 0.86842105, 0.81578947, 0.81578947,\n",
      "       0.86842105, 0.86842105, 0.81578947, 0.81578947, 0.81578947,\n",
      "       0.86842105, 0.86842105, 0.81578947, 0.81578947, 0.84210526,\n",
      "       0.76315789, 0.81578947, 0.81578947, 0.84210526, 0.81578947,\n",
      "       0.78947368, 0.81578947, 0.81578947, 0.84210526, 0.84210526,\n",
      "       0.86842105, 0.81578947, 0.84210526, 0.84210526, 0.84210526,\n",
      "       0.73684211, 0.78947368, 0.81578947, 0.84210526, 0.84210526,\n",
      "       0.84210526, 0.89473684, 0.78947368, 0.86842105, 0.84210526,\n",
      "       0.92105263, 0.89473684, 0.81578947, 0.84210526, 0.81578947,\n",
      "       0.81578947, 0.84210526, 0.84210526, 0.84210526, 0.86842105,\n",
      "       0.84210526]), 'split9_test_score': array([0.73684211, 0.76315789, 0.73684211, 0.71052632, 0.71052632,\n",
      "       0.73684211, 0.65789474, 0.76315789, 0.71052632, 0.65789474,\n",
      "       0.73684211, 0.76315789, 0.78947368, 0.76315789, 0.73684211,\n",
      "       0.71052632, 0.78947368, 0.73684211, 0.68421053, 0.73684211,\n",
      "       0.76315789, 0.73684211, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.76315789, 0.68421053, 0.73684211, 0.71052632,\n",
      "       0.68421053, 0.76315789, 0.65789474, 0.73684211, 0.71052632,\n",
      "       0.76315789, 0.68421053, 0.76315789, 0.71052632, 0.78947368,\n",
      "       0.73684211, 0.73684211, 0.73684211, 0.71052632, 0.71052632,\n",
      "       0.73684211, 0.71052632, 0.68421053, 0.78947368, 0.68421053,\n",
      "       0.76315789, 0.68421053, 0.71052632, 0.78947368, 0.68421053,\n",
      "       0.71052632, 0.73684211, 0.76315789, 0.76315789, 0.73684211,\n",
      "       0.68421053, 0.65789474, 0.68421053, 0.73684211, 0.65789474,\n",
      "       0.71052632, 0.78947368, 0.78947368, 0.73684211, 0.71052632,\n",
      "       0.76315789, 0.78947368, 0.71052632, 0.71052632, 0.73684211,\n",
      "       0.78947368, 0.76315789, 0.76315789, 0.76315789, 0.78947368,\n",
      "       0.81578947]), 'mean_test_score': array([0.75391363, 0.75148448, 0.73866397, 0.76417004, 0.78232119,\n",
      "       0.78495277, 0.72786775, 0.77206478, 0.77192982, 0.74865047,\n",
      "       0.751417  , 0.75411606, 0.75404858, 0.751417  , 0.74892038,\n",
      "       0.75107962, 0.78265857, 0.77469636, 0.72807018, 0.75411606,\n",
      "       0.75654521, 0.75411606, 0.75411606, 0.73589744, 0.74622132,\n",
      "       0.77476383, 0.78259109, 0.74358974, 0.76950067, 0.74358974,\n",
      "       0.73556005, 0.73832659, 0.75910931, 0.74102564, 0.74871795,\n",
      "       0.76443995, 0.74095816, 0.74649123, 0.74358974, 0.74615385,\n",
      "       0.76707152, 0.75661269, 0.74608637, 0.75128205, 0.76929825,\n",
      "       0.72813765, 0.73603239, 0.73063428, 0.77213225, 0.73589744,\n",
      "       0.7488529 , 0.73562753, 0.75904184, 0.76437247, 0.74095816,\n",
      "       0.75937922, 0.73603239, 0.74615385, 0.75674764, 0.76450742,\n",
      "       0.72516869, 0.73556005, 0.76929825, 0.75674764, 0.75128205,\n",
      "       0.74898785, 0.75917679, 0.74615385, 0.76700405, 0.7562753 ,\n",
      "       0.75425101, 0.75931174, 0.73326586, 0.73609987, 0.75411606,\n",
      "       0.76707152, 0.76700405, 0.7645749 , 0.74871795, 0.751417  ,\n",
      "       0.77982456]), 'std_test_score': array([0.08565092, 0.07873141, 0.05324058, 0.06056978, 0.05216688,\n",
      "       0.06425938, 0.04285792, 0.04704493, 0.06119926, 0.08940366,\n",
      "       0.08207703, 0.0758575 , 0.07253837, 0.06160132, 0.08078501,\n",
      "       0.06401902, 0.05931819, 0.07561478, 0.08032921, 0.06893115,\n",
      "       0.0607878 , 0.08241527, 0.06563493, 0.06924813, 0.08171579,\n",
      "       0.08855144, 0.06959024, 0.06555774, 0.07134663, 0.06427493,\n",
      "       0.08349556, 0.07142865, 0.07059397, 0.0695765 , 0.0650881 ,\n",
      "       0.05764193, 0.08164612, 0.07132675, 0.06112928, 0.06500382,\n",
      "       0.07910109, 0.07962616, 0.05269128, 0.0682921 , 0.05293302,\n",
      "       0.05080882, 0.06974839, 0.08072263, 0.07032583, 0.09162249,\n",
      "       0.06746478, 0.06752549, 0.06909361, 0.05987768, 0.07133147,\n",
      "       0.07133706, 0.05378151, 0.0736407 , 0.07599246, 0.0559932 ,\n",
      "       0.06989071, 0.06165765, 0.05160814, 0.06547035, 0.07687879,\n",
      "       0.06635986, 0.07045158, 0.06673397, 0.06572494, 0.0531719 ,\n",
      "       0.08108393, 0.0697146 , 0.07932253, 0.07507878, 0.07129428,\n",
      "       0.0671231 , 0.06259616, 0.07692749, 0.0683081 , 0.07734819,\n",
      "       0.0696656 ]), 'rank_test_score': array([40, 41, 66, 22,  4,  1, 80,  9, 10, 53, 42, 34, 39, 42, 49, 47,  2,\n",
      "        7, 79, 38, 31, 36, 34, 71, 55,  6,  3, 60, 11, 60, 74, 67, 26, 63,\n",
      "       52, 20, 64, 54, 60, 56, 14, 30, 59, 45, 12, 78, 70, 77,  8, 71, 50,\n",
      "       73, 27, 21, 64, 23, 69, 56, 28, 19, 81, 74, 12, 28, 45, 48, 25, 58,\n",
      "       17, 32, 33, 24, 76, 68, 36, 14, 16, 18, 51, 42,  5])}\n",
      "The best parameters are {'dense': 20, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 6} with a score of 0.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([13.64881208, 12.48634889, 12.23947093, 13.26500795, 13.56234176,\n",
      "       14.3876826 , 15.07664008, 14.57159564, 14.60995555, 13.24105809,\n",
      "       13.65430124, 14.54712236, 15.23403192, 15.26401289, 15.28186743,\n",
      "       14.04450095, 14.04808283, 14.51010077, 13.27183242, 13.61537361,\n",
      "       12.95290933, 13.75034921, 14.86689181, 15.46683431, 16.2215317 ,\n",
      "       16.15559082, 15.7871891 , 13.60152972, 13.41840022, 13.44074409,\n",
      "       13.98856981, 13.6584491 , 13.26404049, 15.36632688, 17.78952665,\n",
      "       15.79327133, 14.37996325, 14.2809938 , 13.74946322, 14.72259164,\n",
      "       16.52140989, 15.37126265, 15.24040978, 17.14210916, 18.04217799,\n",
      "       16.89437177, 14.9286025 , 16.09355967, 16.38890049, 15.45350072,\n",
      "       15.31856949, 17.0979141 , 16.54405375, 17.48659863, 13.90942688,\n",
      "       13.78001366, 13.76961832, 15.85111442, 15.70735216, 15.09014435,\n",
      "       15.67900784, 16.06034417, 15.68788519, 13.78811107, 13.9513818 ,\n",
      "       14.2116045 , 15.12751834, 14.9716588 , 15.25616887, 16.64789922,\n",
      "       16.38629234, 15.17951789, 13.80825551, 15.12057362, 14.2831948 ,\n",
      "       15.21279769, 15.42154109, 15.15433011, 17.46409926, 16.72965102,\n",
      "       14.93416355]), 'std_fit_time': array([0.64448072, 0.56252908, 0.599586  , 1.74053224, 1.0938157 ,\n",
      "       0.72299003, 0.74897823, 0.8089545 , 0.88291178, 1.01349062,\n",
      "       0.91486858, 1.34358883, 0.70312948, 1.19056094, 0.82930169,\n",
      "       0.4554778 , 0.8230562 , 0.82003252, 0.90828413, 0.60653682,\n",
      "       0.64261744, 1.21079945, 0.89906943, 0.53068748, 0.48537426,\n",
      "       0.68091561, 0.99863606, 0.97090643, 0.9184751 , 0.73049161,\n",
      "       0.4762152 , 0.56614873, 0.71266855, 0.91520248, 0.88810866,\n",
      "       1.36119142, 0.9947763 , 0.47249047, 0.61979799, 1.65629749,\n",
      "       1.37560955, 0.40376908, 0.54572242, 0.65839511, 0.6878446 ,\n",
      "       1.60538912, 1.04319965, 1.03422537, 0.52939884, 1.00128572,\n",
      "       1.04700863, 0.84059289, 0.87022102, 1.16343496, 0.90900007,\n",
      "       0.49184157, 0.52106582, 1.33587405, 0.69177851, 0.68682011,\n",
      "       0.95767809, 1.07121009, 0.83635798, 0.78162192, 0.5238286 ,\n",
      "       0.82186229, 0.82809731, 0.59178408, 0.84781679, 0.71729701,\n",
      "       0.51212336, 0.37938166, 0.86854557, 0.76173486, 0.64499052,\n",
      "       0.53693863, 0.27407179, 0.60856862, 1.28473515, 0.79315795,\n",
      "       0.99343022]), 'mean_score_time': array([0.7137228 , 0.58325708, 0.57008758, 0.57949343, 0.60022278,\n",
      "       0.6651381 , 0.6818187 , 0.7361583 , 0.66581707, 0.7315259 ,\n",
      "       0.68791344, 0.7944993 , 0.71951258, 0.72040653, 0.65508077,\n",
      "       0.59928126, 0.64488926, 0.66528361, 0.67148995, 0.64887433,\n",
      "       0.73057752, 0.64895003, 0.71542301, 0.70874703, 0.7643127 ,\n",
      "       0.71626072, 0.64307182, 0.75835032, 0.69883845, 0.64760761,\n",
      "       0.72327018, 0.68273463, 0.6606096 , 0.75003688, 0.85920422,\n",
      "       0.82835112, 0.74465568, 0.70226216, 0.69205387, 0.71102579,\n",
      "       0.82029579, 0.74405193, 0.81486771, 0.87619793, 0.81715531,\n",
      "       0.75418839, 0.79910419, 0.73510058, 0.68657365, 0.75111461,\n",
      "       0.80184402, 0.77024252, 0.82300179, 0.91281152, 0.79927275,\n",
      "       0.74027705, 0.83445385, 0.80001304, 0.75876975, 0.72332039,\n",
      "       0.82764051, 0.80976844, 0.80670762, 0.79629061, 0.83780828,\n",
      "       0.74190717, 0.76557102, 0.86805942, 0.81977148, 0.86151912,\n",
      "       0.75581048, 0.79133813, 0.77095437, 0.80779922, 0.86676831,\n",
      "       0.88113501, 0.86122189, 0.79989722, 0.8403111 , 0.93121097,\n",
      "       0.49593558]), 'std_score_time': array([0.29398144, 0.10562022, 0.22383996, 0.19833088, 0.22087018,\n",
      "       0.45920132, 0.20142625, 0.21470455, 0.18093527, 0.24433285,\n",
      "       0.34799103, 0.36460225, 0.29137441, 0.30892514, 0.2054645 ,\n",
      "       0.14826097, 0.20955559, 0.22060068, 0.20657753, 0.19649742,\n",
      "       0.27661211, 0.17523694, 0.24792961, 0.29776413, 0.32692863,\n",
      "       0.22065771, 0.11965304, 0.28811712, 0.20696712, 0.18341045,\n",
      "       0.21546964, 0.24670712, 0.20826793, 0.1934234 , 0.31798942,\n",
      "       0.2454828 , 0.22383143, 0.2108075 , 0.24858331, 0.14042387,\n",
      "       0.1041055 , 0.1509085 , 0.21678964, 0.15900352, 0.11585202,\n",
      "       0.23093773, 0.2612121 , 0.15148154, 0.17541929, 0.15210339,\n",
      "       0.1607367 , 0.19316741, 0.18886924, 0.17199584, 0.14660776,\n",
      "       0.16232209, 0.31659535, 0.19047754, 0.14691503, 0.18050391,\n",
      "       0.26626467, 0.24284857, 0.21699205, 0.28276993, 0.17530324,\n",
      "       0.11672328, 0.09646411, 0.15505892, 0.16688496, 0.17663529,\n",
      "       0.15902718, 0.2190615 , 0.16210854, 0.12862516, 0.08293848,\n",
      "       0.16049469, 0.12482209, 0.22347903, 0.07553558, 0.11590347,\n",
      "       0.29065053]), 'param_dense': masked_array(data=[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 60,\n",
      "                   60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60,\n",
      "                   60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 120,\n",
      "                   120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "                   120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n",
      "                   120, 120, 120, 120],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_dropout_r': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6,\n",
      "                   0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
      "                   0.6, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6, 0.6,\n",
      "                   0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_filter_num': masked_array(data=[8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16,\n",
      "                   32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8,\n",
      "                   16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
      "                   32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
      "                   16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
      "                   8, 16, 16, 16, 32, 32, 32],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_ker_size': masked_array(data=[2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6,\n",
      "                   2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6,\n",
      "                   2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6,\n",
      "                   2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6, 2, 4, 6,\n",
      "                   2, 4, 6, 2, 4, 6, 2, 4, 6],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'dense': 20, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 6}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 2}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 4}, {'dense': 20, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 6}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 2}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 4}, {'dense': 60, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 8, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.5, 'filter_num': 32, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 8, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 16, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.6, 'filter_num': 32, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 8, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 16, 'ker_size': 6}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 2}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 4}, {'dense': 120, 'dropout_r': 0.7, 'filter_num': 32, 'ker_size': 6}], 'split0_test_score': array([0.76923077, 0.74358974, 0.66666667, 0.82051282, 0.76923077,\n",
      "       0.76923077, 0.74358974, 0.74358974, 0.74358974, 0.74358974,\n",
      "       0.69230769, 0.66666667, 0.71794872, 0.74358974, 0.71794872,\n",
      "       0.74358974, 0.76923077, 0.74358974, 0.66666667, 0.69230769,\n",
      "       0.69230769, 0.71794872, 0.71794872, 0.69230769, 0.71794872,\n",
      "       0.71794872, 0.71794872, 0.69230769, 0.74358974, 0.71794872,\n",
      "       0.74358974, 0.71794872, 0.74358974, 0.71794872, 0.66666667,\n",
      "       0.76923077, 0.66666667, 0.66666667, 0.71794872, 0.74358974,\n",
      "       0.71794872, 0.74358974, 0.74358974, 0.71794872, 0.74358974,\n",
      "       0.69230769, 0.69230769, 0.61538462, 0.71794872, 0.66666667,\n",
      "       0.66666667, 0.74358974, 0.69230769, 0.71794872, 0.69230769,\n",
      "       0.71794872, 0.71794872, 0.71794872, 0.71794872, 0.69230769,\n",
      "       0.74358974, 0.69230769, 0.74358974, 0.71794872, 0.71794872,\n",
      "       0.69230769, 0.74358974, 0.76923077, 0.69230769, 0.74358974,\n",
      "       0.69230769, 0.71794872, 0.66666667, 0.61538462, 0.66666667,\n",
      "       0.76923077, 0.71794872, 0.71794872, 0.69230769, 0.74358974,\n",
      "       0.71794872]), 'split1_test_score': array([0.87179487, 0.84615385, 0.71794872, 0.82051282, 0.87179487,\n",
      "       0.87179487, 0.79487179, 0.84615385, 0.87179487, 0.84615385,\n",
      "       0.87179487, 0.84615385, 0.84615385, 0.82051282, 0.87179487,\n",
      "       0.87179487, 0.84615385, 0.8974359 , 0.79487179, 0.79487179,\n",
      "       0.82051282, 0.87179487, 0.79487179, 0.84615385, 0.87179487,\n",
      "       0.8974359 , 0.87179487, 0.84615385, 0.8974359 , 0.84615385,\n",
      "       0.87179487, 0.8974359 , 0.82051282, 0.87179487, 0.87179487,\n",
      "       0.82051282, 0.84615385, 0.82051282, 0.82051282, 0.84615385,\n",
      "       0.87179487, 0.84615385, 0.82051282, 0.87179487, 0.82051282,\n",
      "       0.76923077, 0.82051282, 0.84615385, 0.87179487, 0.87179487,\n",
      "       0.8974359 , 0.87179487, 0.8974359 , 0.84615385, 0.84615385,\n",
      "       0.84615385, 0.71794872, 0.87179487, 0.84615385, 0.82051282,\n",
      "       0.84615385, 0.84615385, 0.84615385, 0.76923077, 0.8974359 ,\n",
      "       0.79487179, 0.84615385, 0.84615385, 0.82051282, 0.84615385,\n",
      "       0.76923077, 0.82051282, 0.84615385, 0.84615385, 0.8974359 ,\n",
      "       0.84615385, 0.84615385, 0.87179487, 0.84615385, 0.87179487,\n",
      "       0.87179487]), 'split2_test_score': array([0.82051282, 0.84615385, 0.82051282, 0.84615385, 0.84615385,\n",
      "       0.84615385, 0.76923077, 0.82051282, 0.84615385, 0.8974359 ,\n",
      "       0.84615385, 0.87179487, 0.84615385, 0.84615385, 0.84615385,\n",
      "       0.84615385, 0.82051282, 0.82051282, 0.8974359 , 0.82051282,\n",
      "       0.87179487, 0.87179487, 0.84615385, 0.82051282, 0.84615385,\n",
      "       0.84615385, 0.84615385, 0.79487179, 0.82051282, 0.82051282,\n",
      "       0.84615385, 0.76923077, 0.84615385, 0.82051282, 0.82051282,\n",
      "       0.79487179, 0.82051282, 0.82051282, 0.82051282, 0.82051282,\n",
      "       0.82051282, 0.87179487, 0.82051282, 0.84615385, 0.84615385,\n",
      "       0.82051282, 0.79487179, 0.79487179, 0.87179487, 0.84615385,\n",
      "       0.79487179, 0.79487179, 0.84615385, 0.84615385, 0.79487179,\n",
      "       0.79487179, 0.82051282, 0.79487179, 0.84615385, 0.82051282,\n",
      "       0.84615385, 0.82051282, 0.84615385, 0.87179487, 0.79487179,\n",
      "       0.82051282, 0.79487179, 0.82051282, 0.87179487, 0.79487179,\n",
      "       0.87179487, 0.82051282, 0.84615385, 0.79487179, 0.79487179,\n",
      "       0.84615385, 0.82051282, 0.82051282, 0.84615385, 0.74358974,\n",
      "       0.87179487]), 'split3_test_score': array([0.79487179, 0.71794872, 0.71794872, 0.76923077, 0.76923077,\n",
      "       0.84615385, 0.71794872, 0.76923077, 0.79487179, 0.76923077,\n",
      "       0.76923077, 0.71794872, 0.74358974, 0.74358974, 0.69230769,\n",
      "       0.76923077, 0.74358974, 0.76923077, 0.71794872, 0.79487179,\n",
      "       0.74358974, 0.69230769, 0.76923077, 0.71794872, 0.74358974,\n",
      "       0.79487179, 0.82051282, 0.76923077, 0.76923077, 0.74358974,\n",
      "       0.76923077, 0.74358974, 0.71794872, 0.69230769, 0.74358974,\n",
      "       0.76923077, 0.79487179, 0.74358974, 0.76923077, 0.66666667,\n",
      "       0.79487179, 0.74358974, 0.74358974, 0.74358974, 0.79487179,\n",
      "       0.71794872, 0.74358974, 0.79487179, 0.76923077, 0.74358974,\n",
      "       0.69230769, 0.71794872, 0.74358974, 0.74358974, 0.76923077,\n",
      "       0.74358974, 0.71794872, 0.74358974, 0.69230769, 0.74358974,\n",
      "       0.71794872, 0.74358974, 0.76923077, 0.74358974, 0.76923077,\n",
      "       0.74358974, 0.74358974, 0.71794872, 0.76923077, 0.76923077,\n",
      "       0.71794872, 0.76923077, 0.74358974, 0.69230769, 0.69230769,\n",
      "       0.74358974, 0.76923077, 0.71794872, 0.74358974, 0.79487179,\n",
      "       0.74358974]), 'split4_test_score': array([0.58974359, 0.64102564, 0.69230769, 0.64102564, 0.71794872,\n",
      "       0.69230769, 0.69230769, 0.69230769, 0.69230769, 0.58974359,\n",
      "       0.66666667, 0.66666667, 0.61538462, 0.66666667, 0.61538462,\n",
      "       0.66666667, 0.66666667, 0.64102564, 0.61538462, 0.66666667,\n",
      "       0.71794872, 0.61538462, 0.66666667, 0.64102564, 0.61538462,\n",
      "       0.64102564, 0.69230769, 0.66666667, 0.69230769, 0.64102564,\n",
      "       0.64102564, 0.64102564, 0.66666667, 0.64102564, 0.66666667,\n",
      "       0.66666667, 0.61538462, 0.61538462, 0.66666667, 0.69230769,\n",
      "       0.58974359, 0.64102564, 0.66666667, 0.66666667, 0.69230769,\n",
      "       0.64102564, 0.58974359, 0.64102564, 0.64102564, 0.64102564,\n",
      "       0.69230769, 0.69230769, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.64102564, 0.69230769, 0.71794872, 0.66666667, 0.66666667,\n",
      "       0.66666667, 0.66666667, 0.74358974, 0.66666667, 0.66666667,\n",
      "       0.61538462, 0.66666667, 0.61538462, 0.69230769, 0.74358974,\n",
      "       0.64102564, 0.66666667, 0.58974359, 0.64102564, 0.71794872,\n",
      "       0.69230769, 0.64102564, 0.64102564, 0.66666667, 0.61538462,\n",
      "       0.71794872]), 'split5_test_score': array([0.66666667, 0.64102564, 0.69230769, 0.71794872, 0.74358974,\n",
      "       0.69230769, 0.69230769, 0.74358974, 0.71794872, 0.66666667,\n",
      "       0.61538462, 0.66666667, 0.69230769, 0.64102564, 0.66666667,\n",
      "       0.69230769, 0.74358974, 0.74358974, 0.64102564, 0.66666667,\n",
      "       0.66666667, 0.66666667, 0.64102564, 0.64102564, 0.64102564,\n",
      "       0.69230769, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.61538462, 0.66666667, 0.74358974, 0.66666667, 0.71794872,\n",
      "       0.69230769, 0.69230769, 0.66666667, 0.64102564, 0.69230769,\n",
      "       0.71794872, 0.64102564, 0.69230769, 0.66666667, 0.76923077,\n",
      "       0.66666667, 0.66666667, 0.66666667, 0.71794872, 0.58974359,\n",
      "       0.69230769, 0.64102564, 0.71794872, 0.71794872, 0.66666667,\n",
      "       0.69230769, 0.64102564, 0.61538462, 0.66666667, 0.74358974,\n",
      "       0.61538462, 0.71794872, 0.71794872, 0.66666667, 0.66666667,\n",
      "       0.71794872, 0.71794872, 0.69230769, 0.69230769, 0.71794872,\n",
      "       0.69230769, 0.66666667, 0.66666667, 0.69230769, 0.66666667,\n",
      "       0.61538462, 0.74358974, 0.69230769, 0.69230769, 0.69230769,\n",
      "       0.74358974]), 'split6_test_score': array([0.73684211, 0.76315789, 0.76315789, 0.73684211, 0.76315789,\n",
      "       0.81578947, 0.71052632, 0.73684211, 0.81578947, 0.81578947,\n",
      "       0.84210526, 0.78947368, 0.73684211, 0.73684211, 0.78947368,\n",
      "       0.71052632, 0.84210526, 0.78947368, 0.78947368, 0.84210526,\n",
      "       0.76315789, 0.76315789, 0.78947368, 0.71052632, 0.71052632,\n",
      "       0.78947368, 0.81578947, 0.76315789, 0.78947368, 0.76315789,\n",
      "       0.68421053, 0.65789474, 0.81578947, 0.71052632, 0.71052632,\n",
      "       0.78947368, 0.68421053, 0.81578947, 0.76315789, 0.65789474,\n",
      "       0.78947368, 0.76315789, 0.71052632, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.78947368, 0.78947368, 0.76315789, 0.81578947,\n",
      "       0.78947368, 0.71052632, 0.73684211, 0.73684211, 0.65789474,\n",
      "       0.84210526, 0.78947368, 0.65789474, 0.84210526, 0.81578947,\n",
      "       0.68421053, 0.73684211, 0.78947368, 0.81578947, 0.78947368,\n",
      "       0.81578947, 0.65789474, 0.73684211, 0.78947368, 0.68421053,\n",
      "       0.71052632, 0.73684211, 0.73684211, 0.76315789, 0.81578947,\n",
      "       0.78947368, 0.81578947, 0.86842105, 0.68421053, 0.68421053,\n",
      "       0.81578947]), 'split7_test_score': array([0.68421053, 0.68421053, 0.73684211, 0.76315789, 0.78947368,\n",
      "       0.73684211, 0.71052632, 0.76315789, 0.71052632, 0.71052632,\n",
      "       0.68421053, 0.71052632, 0.71052632, 0.73684211, 0.71052632,\n",
      "       0.71052632, 0.73684211, 0.71052632, 0.71052632, 0.68421053,\n",
      "       0.71052632, 0.76315789, 0.71052632, 0.71052632, 0.71052632,\n",
      "       0.68421053, 0.76315789, 0.71052632, 0.71052632, 0.71052632,\n",
      "       0.68421053, 0.73684211, 0.71052632, 0.73684211, 0.76315789,\n",
      "       0.71052632, 0.73684211, 0.73684211, 0.71052632, 0.73684211,\n",
      "       0.76315789, 0.71052632, 0.71052632, 0.71052632, 0.71052632,\n",
      "       0.71052632, 0.73684211, 0.65789474, 0.73684211, 0.68421053,\n",
      "       0.71052632, 0.68421053, 0.76315789, 0.73684211, 0.78947368,\n",
      "       0.73684211, 0.71052632, 0.73684211, 0.68421053, 0.76315789,\n",
      "       0.71052632, 0.68421053, 0.73684211, 0.73684211, 0.71052632,\n",
      "       0.73684211, 0.73684211, 0.68421053, 0.73684211, 0.71052632,\n",
      "       0.76315789, 0.71052632, 0.71052632, 0.76315789, 0.73684211,\n",
      "       0.76315789, 0.71052632, 0.71052632, 0.71052632, 0.71052632,\n",
      "       0.65789474]), 'split8_test_score': array([0.86842105, 0.86842105, 0.84210526, 0.81578947, 0.84210526,\n",
      "       0.84210526, 0.78947368, 0.84210526, 0.81578947, 0.78947368,\n",
      "       0.78947368, 0.84210526, 0.84210526, 0.81578947, 0.84210526,\n",
      "       0.78947368, 0.86842105, 0.89473684, 0.76315789, 0.84210526,\n",
      "       0.81578947, 0.84210526, 0.84210526, 0.81578947, 0.84210526,\n",
      "       0.92105263, 0.86842105, 0.84210526, 0.86842105, 0.81578947,\n",
      "       0.81578947, 0.78947368, 0.86842105, 0.81578947, 0.81578947,\n",
      "       0.86842105, 0.86842105, 0.81578947, 0.81578947, 0.81578947,\n",
      "       0.86842105, 0.86842105, 0.81578947, 0.81578947, 0.84210526,\n",
      "       0.76315789, 0.81578947, 0.81578947, 0.84210526, 0.81578947,\n",
      "       0.78947368, 0.81578947, 0.81578947, 0.84210526, 0.84210526,\n",
      "       0.86842105, 0.81578947, 0.84210526, 0.84210526, 0.84210526,\n",
      "       0.73684211, 0.78947368, 0.81578947, 0.84210526, 0.84210526,\n",
      "       0.84210526, 0.89473684, 0.78947368, 0.86842105, 0.84210526,\n",
      "       0.92105263, 0.89473684, 0.81578947, 0.84210526, 0.81578947,\n",
      "       0.81578947, 0.84210526, 0.84210526, 0.84210526, 0.86842105,\n",
      "       0.84210526]), 'split9_test_score': array([0.73684211, 0.76315789, 0.73684211, 0.71052632, 0.71052632,\n",
      "       0.73684211, 0.65789474, 0.76315789, 0.71052632, 0.65789474,\n",
      "       0.73684211, 0.76315789, 0.78947368, 0.76315789, 0.73684211,\n",
      "       0.71052632, 0.78947368, 0.73684211, 0.68421053, 0.73684211,\n",
      "       0.76315789, 0.73684211, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.76315789, 0.68421053, 0.73684211, 0.71052632,\n",
      "       0.68421053, 0.76315789, 0.65789474, 0.73684211, 0.71052632,\n",
      "       0.76315789, 0.68421053, 0.76315789, 0.71052632, 0.78947368,\n",
      "       0.73684211, 0.73684211, 0.73684211, 0.71052632, 0.71052632,\n",
      "       0.73684211, 0.71052632, 0.68421053, 0.78947368, 0.68421053,\n",
      "       0.76315789, 0.68421053, 0.71052632, 0.78947368, 0.68421053,\n",
      "       0.71052632, 0.73684211, 0.76315789, 0.76315789, 0.73684211,\n",
      "       0.68421053, 0.65789474, 0.68421053, 0.73684211, 0.65789474,\n",
      "       0.71052632, 0.78947368, 0.78947368, 0.73684211, 0.71052632,\n",
      "       0.76315789, 0.78947368, 0.71052632, 0.71052632, 0.73684211,\n",
      "       0.78947368, 0.76315789, 0.76315789, 0.76315789, 0.78947368,\n",
      "       0.81578947]), 'mean_test_score': array([0.75391363, 0.75148448, 0.73866397, 0.76417004, 0.78232119,\n",
      "       0.78495277, 0.72786775, 0.77206478, 0.77192982, 0.74865047,\n",
      "       0.751417  , 0.75411606, 0.75404858, 0.751417  , 0.74892038,\n",
      "       0.75107962, 0.78265857, 0.77469636, 0.72807018, 0.75411606,\n",
      "       0.75654521, 0.75411606, 0.75411606, 0.73589744, 0.74622132,\n",
      "       0.77476383, 0.78259109, 0.74358974, 0.76950067, 0.74358974,\n",
      "       0.73556005, 0.73832659, 0.75910931, 0.74102564, 0.74871795,\n",
      "       0.76443995, 0.74095816, 0.74649123, 0.74358974, 0.74615385,\n",
      "       0.76707152, 0.75661269, 0.74608637, 0.75128205, 0.76929825,\n",
      "       0.72813765, 0.73603239, 0.73063428, 0.77213225, 0.73589744,\n",
      "       0.7488529 , 0.73562753, 0.75904184, 0.76437247, 0.74095816,\n",
      "       0.75937922, 0.73603239, 0.74615385, 0.75674764, 0.76450742,\n",
      "       0.72516869, 0.73556005, 0.76929825, 0.75674764, 0.75128205,\n",
      "       0.74898785, 0.75917679, 0.74615385, 0.76700405, 0.7562753 ,\n",
      "       0.75425101, 0.75931174, 0.73326586, 0.73609987, 0.75411606,\n",
      "       0.76707152, 0.76700405, 0.7645749 , 0.74871795, 0.751417  ,\n",
      "       0.77982456]), 'std_test_score': array([0.08565092, 0.07873141, 0.05324058, 0.06056978, 0.05216688,\n",
      "       0.06425938, 0.04285792, 0.04704493, 0.06119926, 0.08940366,\n",
      "       0.08207703, 0.0758575 , 0.07253837, 0.06160132, 0.08078501,\n",
      "       0.06401902, 0.05931819, 0.07561478, 0.08032921, 0.06893115,\n",
      "       0.0607878 , 0.08241527, 0.06563493, 0.06924813, 0.08171579,\n",
      "       0.08855144, 0.06959024, 0.06555774, 0.07134663, 0.06427493,\n",
      "       0.08349556, 0.07142865, 0.07059397, 0.0695765 , 0.0650881 ,\n",
      "       0.05764193, 0.08164612, 0.07132675, 0.06112928, 0.06500382,\n",
      "       0.07910109, 0.07962616, 0.05269128, 0.0682921 , 0.05293302,\n",
      "       0.05080882, 0.06974839, 0.08072263, 0.07032583, 0.09162249,\n",
      "       0.06746478, 0.06752549, 0.06909361, 0.05987768, 0.07133147,\n",
      "       0.07133706, 0.05378151, 0.0736407 , 0.07599246, 0.0559932 ,\n",
      "       0.06989071, 0.06165765, 0.05160814, 0.06547035, 0.07687879,\n",
      "       0.06635986, 0.07045158, 0.06673397, 0.06572494, 0.0531719 ,\n",
      "       0.08108393, 0.0697146 , 0.07932253, 0.07507878, 0.07129428,\n",
      "       0.0671231 , 0.06259616, 0.07692749, 0.0683081 , 0.07734819,\n",
      "       0.0696656 ]), 'rank_test_score': array([40, 41, 66, 22,  4,  1, 80,  9, 10, 53, 42, 34, 39, 42, 49, 47,  2,\n",
      "        7, 79, 38, 31, 36, 34, 71, 55,  6,  3, 60, 11, 60, 74, 67, 26, 63,\n",
      "       52, 20, 64, 54, 60, 56, 14, 30, 59, 45, 12, 78, 70, 77,  8, 71, 50,\n",
      "       73, 27, 21, 64, 23, 69, 56, 28, 19, 81, 74, 12, 28, 45, 48, 25, 58,\n",
      "       17, 32, 33, 24, 76, 68, 36, 14, 16, 18, 51, 42,  5])}\n",
      "The best parameters are {'dense': 20, 'dropout_r': 0.5, 'filter_num': 16, 'ker_size': 6} with a score of 0.78\n"
     ]
    }
   ],
   "source": [
    "# Print grid results and display best parameters\n",
    "print(grid.cv_results_)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model for Tensorflow to display Accuracy Vs. Epoch and Loss Vs. Epoch\n",
    "def create_model_tf():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=16, kernel_size=6, activation='relu', input_shape=(n_features, 1)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(n_outputs+1, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 2.4141 - accuracy: 0.2195 - val_loss: 2.4169 - val_accuracy: 0.2375\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.3261 - accuracy: 0.3428 - val_loss: 2.3496 - val_accuracy: 0.2313\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.2629 - accuracy: 0.3386 - val_loss: 2.2888 - val_accuracy: 0.2438\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1427 - accuracy: 0.3676 - val_loss: 2.2312 - val_accuracy: 0.2500\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.0898 - accuracy: 0.3498 - val_loss: 2.1632 - val_accuracy: 0.3000\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.0153 - accuracy: 0.3507 - val_loss: 2.0866 - val_accuracy: 0.3438\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8767 - accuracy: 0.4234 - val_loss: 2.0149 - val_accuracy: 0.3875\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8831 - accuracy: 0.3926 - val_loss: 1.9375 - val_accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7765 - accuracy: 0.4484 - val_loss: 1.8578 - val_accuracy: 0.4125\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6467 - accuracy: 0.4650 - val_loss: 1.7753 - val_accuracy: 0.4313\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6320 - accuracy: 0.4927 - val_loss: 1.6958 - val_accuracy: 0.4500\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5345 - accuracy: 0.5148 - val_loss: 1.6192 - val_accuracy: 0.4563\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.4593 - accuracy: 0.5420 - val_loss: 1.5500 - val_accuracy: 0.4625\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.4458 - accuracy: 0.5110 - val_loss: 1.4833 - val_accuracy: 0.4812\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.4239 - accuracy: 0.5186 - val_loss: 1.4257 - val_accuracy: 0.4812\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.3810 - accuracy: 0.5108 - val_loss: 1.3771 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2789 - accuracy: 0.5379 - val_loss: 1.3451 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.3115 - accuracy: 0.5266 - val_loss: 1.3072 - val_accuracy: 0.5063\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2026 - accuracy: 0.5599 - val_loss: 1.2811 - val_accuracy: 0.5250\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2456 - accuracy: 0.5526 - val_loss: 1.2551 - val_accuracy: 0.5312\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1623 - accuracy: 0.5645 - val_loss: 1.2236 - val_accuracy: 0.5500\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1130 - accuracy: 0.5912 - val_loss: 1.1895 - val_accuracy: 0.5437\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.0797 - accuracy: 0.6085 - val_loss: 1.1600 - val_accuracy: 0.5562\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0668 - accuracy: 0.6051 - val_loss: 1.1453 - val_accuracy: 0.5375\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.0264 - accuracy: 0.6322 - val_loss: 1.1291 - val_accuracy: 0.5500\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9950 - accuracy: 0.6130 - val_loss: 1.1084 - val_accuracy: 0.5500\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9948 - accuracy: 0.6323 - val_loss: 1.0786 - val_accuracy: 0.5562\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9722 - accuracy: 0.6335 - val_loss: 1.0565 - val_accuracy: 0.5625\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9182 - accuracy: 0.6487 - val_loss: 1.0223 - val_accuracy: 0.5750\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8925 - accuracy: 0.6734 - val_loss: 1.0207 - val_accuracy: 0.5500\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9286 - accuracy: 0.6491 - val_loss: 1.0235 - val_accuracy: 0.5562\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9308 - accuracy: 0.6322 - val_loss: 0.9787 - val_accuracy: 0.5813\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.8859 - accuracy: 0.6816 - val_loss: 0.9731 - val_accuracy: 0.5938\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.8673 - accuracy: 0.6940 - val_loss: 0.9547 - val_accuracy: 0.6187\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8280 - accuracy: 0.6414 - val_loss: 0.9526 - val_accuracy: 0.5875\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8509 - accuracy: 0.7088 - val_loss: 0.9381 - val_accuracy: 0.5875\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8425 - accuracy: 0.7105 - val_loss: 0.9168 - val_accuracy: 0.5938\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8562 - accuracy: 0.6721 - val_loss: 0.8947 - val_accuracy: 0.6375\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7819 - accuracy: 0.7137 - val_loss: 0.8833 - val_accuracy: 0.6500\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.7514 - accuracy: 0.7010 - val_loss: 0.8748 - val_accuracy: 0.6562\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7498 - accuracy: 0.7295 - val_loss: 0.8772 - val_accuracy: 0.6062\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7956 - accuracy: 0.6647 - val_loss: 0.8737 - val_accuracy: 0.5938\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7175 - accuracy: 0.7206 - val_loss: 0.8537 - val_accuracy: 0.6687\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7233 - accuracy: 0.7010 - val_loss: 0.8519 - val_accuracy: 0.6187\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7597 - accuracy: 0.7216 - val_loss: 0.8358 - val_accuracy: 0.6375\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.7692 - accuracy: 0.7093 - val_loss: 0.8250 - val_accuracy: 0.6438\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.7119 - accuracy: 0.7410 - val_loss: 0.8261 - val_accuracy: 0.6187\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7588 - accuracy: 0.6956 - val_loss: 0.8234 - val_accuracy: 0.6562\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7102 - accuracy: 0.7745 - val_loss: 0.8045 - val_accuracy: 0.6938\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7024 - accuracy: 0.7067 - val_loss: 0.7932 - val_accuracy: 0.7188\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.6803 - accuracy: 0.7353 - val_loss: 0.7967 - val_accuracy: 0.6562\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7285 - accuracy: 0.7269 - val_loss: 0.7844 - val_accuracy: 0.6687\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7123 - accuracy: 0.7662 - val_loss: 0.7692 - val_accuracy: 0.6938\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6339 - accuracy: 0.7722 - val_loss: 0.7582 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6823 - accuracy: 0.7625 - val_loss: 0.7612 - val_accuracy: 0.7375\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6775 - accuracy: 0.7571 - val_loss: 0.7670 - val_accuracy: 0.6938\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7034 - accuracy: 0.7485 - val_loss: 0.7544 - val_accuracy: 0.7625\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6600 - accuracy: 0.7576 - val_loss: 0.7775 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.6784 - accuracy: 0.7409 - val_loss: 0.7549 - val_accuracy: 0.7750\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.6467 - accuracy: 0.7482 - val_loss: 0.7521 - val_accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6203 - accuracy: 0.7814 - val_loss: 0.7459 - val_accuracy: 0.7375\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5861 - accuracy: 0.8060 - val_loss: 0.7452 - val_accuracy: 0.7188\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6373 - accuracy: 0.7526 - val_loss: 0.7306 - val_accuracy: 0.7625\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6713 - accuracy: 0.7441 - val_loss: 0.7388 - val_accuracy: 0.6875\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6494 - accuracy: 0.7620 - val_loss: 0.7395 - val_accuracy: 0.6812\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6848 - accuracy: 0.6961 - val_loss: 0.7179 - val_accuracy: 0.7375\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6577 - accuracy: 0.7290 - val_loss: 0.7108 - val_accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6677 - accuracy: 0.7666 - val_loss: 0.7070 - val_accuracy: 0.7437\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6374 - accuracy: 0.7678 - val_loss: 0.7217 - val_accuracy: 0.7375\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6615 - accuracy: 0.7563 - val_loss: 0.7227 - val_accuracy: 0.7312\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6580 - accuracy: 0.7444 - val_loss: 0.7112 - val_accuracy: 0.7375\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6527 - accuracy: 0.7375 - val_loss: 0.6976 - val_accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6649 - accuracy: 0.7423 - val_loss: 0.6816 - val_accuracy: 0.7937\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5936 - accuracy: 0.7391 - val_loss: 0.6955 - val_accuracy: 0.7750\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6038 - accuracy: 0.7575 - val_loss: 0.7046 - val_accuracy: 0.7375\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6143 - accuracy: 0.7715 - val_loss: 0.6928 - val_accuracy: 0.7688\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6097 - accuracy: 0.7715 - val_loss: 0.6896 - val_accuracy: 0.7625\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6069 - accuracy: 0.7730 - val_loss: 0.6889 - val_accuracy: 0.7375\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5922 - accuracy: 0.7540 - val_loss: 0.6846 - val_accuracy: 0.7625\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6093 - accuracy: 0.8186 - val_loss: 0.6747 - val_accuracy: 0.7688\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6167 - accuracy: 0.7814 - val_loss: 0.6791 - val_accuracy: 0.7625\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5942 - accuracy: 0.7423 - val_loss: 0.6687 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6095 - accuracy: 0.7551 - val_loss: 0.6740 - val_accuracy: 0.7437\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5736 - accuracy: 0.7934 - val_loss: 0.6550 - val_accuracy: 0.8000\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6235 - accuracy: 0.7745 - val_loss: 0.6612 - val_accuracy: 0.7812\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.7674 - val_loss: 0.6725 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6077 - accuracy: 0.7748 - val_loss: 0.6668 - val_accuracy: 0.7312\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5758 - accuracy: 0.7887 - val_loss: 0.6606 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5319 - accuracy: 0.7951 - val_loss: 0.6540 - val_accuracy: 0.7563\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5938 - accuracy: 0.7537 - val_loss: 0.6398 - val_accuracy: 0.7812\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5640 - accuracy: 0.7787 - val_loss: 0.6485 - val_accuracy: 0.7812\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5331 - accuracy: 0.8003 - val_loss: 0.6527 - val_accuracy: 0.7625\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6177 - accuracy: 0.7613 - val_loss: 0.6415 - val_accuracy: 0.7812\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5609 - accuracy: 0.7855 - val_loss: 0.6351 - val_accuracy: 0.7812\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5883 - accuracy: 0.7676 - val_loss: 0.6413 - val_accuracy: 0.7812\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.8061 - val_loss: 0.6505 - val_accuracy: 0.7563\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.8303 - val_loss: 0.6615 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5676 - accuracy: 0.8204 - val_loss: 0.6525 - val_accuracy: 0.7625\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5575 - accuracy: 0.7898 - val_loss: 0.6434 - val_accuracy: 0.7875\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5952 - accuracy: 0.7721 - val_loss: 0.6432 - val_accuracy: 0.7937\n",
      "0.69887296463233\n",
      "0.8380734285847675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheAr\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    \n",
    "  \"\"\"\n",
    "    Best hyper parameters:\n",
    "    \n",
    "    'dense': 20, \n",
    "    'dropout_r': 0.5, \n",
    "    'filter_num': 16, \n",
    "    'ker_size': 6 \n",
    "    \n",
    "    with a score of 0.78\n",
    "  \"\"\"    \n",
    "\n",
    "  # Regenerate model with best parameters\n",
    "  model = create_model_tf()\n",
    "  model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  # Prepare results for Tensorflow Module (Platform)\n",
    "  logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "  # Perform traning and rough validation\n",
    "  model.fit(x=X_train, \n",
    "            y=y_train, \n",
    "            epochs=100, \n",
    "            validation_data=(X_test, y_test), \n",
    "            callbacks=[tensorboard_callback])\n",
    "\n",
    "  # Return predicted y labels\n",
    "  y_hat = model.predict_classes(X_test, verbose=0)\n",
    "\n",
    "  def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"): # Method from https://medium.com/@plog397/auc-roc-curve-scoring-function-for-multi-class-classification-9822871a6659\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "  def multiclass_f_score(y_test, y_pred, average=\"macro\"): # Method from https://medium.com/@plog397/auc-roc-curve-scoring-function-for-multi-class-classification-9822871a6659\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return f1_score(y_test, y_pred, average=average)\n",
    "\n",
    "  # Display f1 score and AUC score\n",
    "  print(multiclass_f_score(y_test,y_hat))\n",
    "  print(multiclass_roc_auc_score(y_test,y_hat))\n",
    "\n",
    "\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 16600), started 1 day, 13:20:40 ago. (Use '!kill 16600' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-773820475af9610c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-773820475af9610c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for 2D-CNN\n",
    "\n",
    "PIE_datapath = '../data/PIE_32x32/'\n",
    "PIE_test_filenames = ['StTestFile'+str(i)+'.txt' for i in range(1,11)]\n",
    "PIE_train_filenames = ['StTrainFile'+str(i)+'.txt' for i in range(1,11)]\n",
    "\n",
    "\n",
    "PIE_train_data_files = [np.genfromtxt(PIE_datapath+PIE_train_filenames[i],delimiter=' ') for i in range(0,2)]\n",
    "\n",
    "\n",
    "rowData = []\n",
    "\n",
    "for i in PIE_train_data_files:\n",
    "    for row in i:\n",
    "        rowData.append(row)\n",
    "    \n",
    "PIE_train_data = np.array(rowData)\n",
    "\n",
    "PIE_Xtrain = PIE_train_data[:,0:1024]\n",
    "PIE_ytrain = PIE_train_data[:,1024]\n",
    "\n",
    "PIE_test_filename = PIE_test_filenames[0]\n",
    "PIE_test_data = np.genfromtxt(PIE_datapath+PIE_test_filename,delimiter=' ')\n",
    "PIE_Xtest = PIE_test_data[:,0:1024]\n",
    "PIE_ytest = PIE_test_data[:,1024]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "listofimages = []\n",
    "for row in range(PIE_Xtrain.shape[0]):\n",
    "  currimage = PIE_Xtrain[row,0:1024]\n",
    "  currreshaped = np.reshape(currimage,(32,32,1))\n",
    "  listofimages.append(currreshaped)\n",
    "\n",
    "PIE_Xtrain = np.array(listofimages)\n",
    "\n",
    "listofimages = []\n",
    "for row in range(PIE_Xtest.shape[0]):\n",
    "  currimage = PIE_Xtest[row,0:1024]\n",
    "  currreshaped = np.reshape(currimage,(32,32,1))\n",
    "  listofimages.append(currreshaped)\n",
    "\n",
    "PIE_Xtest = np.array(listofimages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.031373]\n",
      "   [0.035294]\n",
      "   [0.035294]\n",
      "   ...\n",
      "   [0.039216]\n",
      "   [0.031373]\n",
      "   [0.035294]]\n",
      "\n",
      "  [[0.035294]\n",
      "   [0.039216]\n",
      "   [0.035294]\n",
      "   ...\n",
      "   [0.039216]\n",
      "   [0.031373]\n",
      "   [0.035294]]\n",
      "\n",
      "  [[0.035294]\n",
      "   [0.035294]\n",
      "   [0.035294]\n",
      "   ...\n",
      "   [0.043137]\n",
      "   [0.039216]\n",
      "   [0.035294]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.027451]\n",
      "   [0.023529]\n",
      "   [0.019608]\n",
      "   ...\n",
      "   [0.019608]\n",
      "   [0.019608]\n",
      "   [0.019608]]\n",
      "\n",
      "  [[0.015686]\n",
      "   [0.019608]\n",
      "   [0.019608]\n",
      "   ...\n",
      "   [0.019608]\n",
      "   [0.019608]\n",
      "   [0.019608]]\n",
      "\n",
      "  [[0.019608]\n",
      "   [0.019608]\n",
      "   [0.019608]\n",
      "   ...\n",
      "   [0.019608]\n",
      "   [0.023529]\n",
      "   [0.019608]]]\n",
      "\n",
      "\n",
      " [[[0.039216]\n",
      "   [0.043137]\n",
      "   [0.043137]\n",
      "   ...\n",
      "   [0.043137]\n",
      "   [0.035294]\n",
      "   [0.035294]]\n",
      "\n",
      "  [[0.05098 ]\n",
      "   [0.05098 ]\n",
      "   [0.047059]\n",
      "   ...\n",
      "   [0.047059]\n",
      "   [0.043137]\n",
      "   [0.039216]]\n",
      "\n",
      "  [[0.070588]\n",
      "   [0.066667]\n",
      "   [0.054902]\n",
      "   ...\n",
      "   [0.047059]\n",
      "   [0.039216]\n",
      "   [0.043137]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.023529]\n",
      "   [0.023529]\n",
      "   [0.027451]\n",
      "   ...\n",
      "   [0.019608]\n",
      "   [0.019608]\n",
      "   [0.019608]]\n",
      "\n",
      "  [[0.019608]\n",
      "   [0.019608]\n",
      "   [0.019608]\n",
      "   ...\n",
      "   [0.023529]\n",
      "   [0.019608]\n",
      "   [0.019608]]\n",
      "\n",
      "  [[0.019608]\n",
      "   [0.019608]\n",
      "   [0.019608]\n",
      "   ...\n",
      "   [0.019608]\n",
      "   [0.023529]\n",
      "   [0.019608]]]\n",
      "\n",
      "\n",
      " [[[0.11373 ]\n",
      "   [0.11373 ]\n",
      "   [0.11373 ]\n",
      "   ...\n",
      "   [0.05098 ]\n",
      "   [0.047059]\n",
      "   [0.047059]]\n",
      "\n",
      "  [[0.14902 ]\n",
      "   [0.1451  ]\n",
      "   [0.13725 ]\n",
      "   ...\n",
      "   [0.058824]\n",
      "   [0.047059]\n",
      "   [0.05098 ]]\n",
      "\n",
      "  [[0.18824 ]\n",
      "   [0.17255 ]\n",
      "   [0.13725 ]\n",
      "   ...\n",
      "   [0.078431]\n",
      "   [0.062745]\n",
      "   [0.05098 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.027451]\n",
      "   [0.027451]\n",
      "   [0.019608]\n",
      "   ...\n",
      "   [0.019608]\n",
      "   [0.019608]\n",
      "   [0.019608]]\n",
      "\n",
      "  [[0.023529]\n",
      "   [0.023529]\n",
      "   [0.023529]\n",
      "   ...\n",
      "   [0.019608]\n",
      "   [0.019608]\n",
      "   [0.019608]]\n",
      "\n",
      "  [[0.023529]\n",
      "   [0.023529]\n",
      "   [0.023529]\n",
      "   ...\n",
      "   [0.019608]\n",
      "   [0.019608]\n",
      "   [0.023529]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.027451]\n",
      "   [0.027451]\n",
      "   [0.023529]\n",
      "   ...\n",
      "   [0.6549  ]\n",
      "   [0.64314 ]\n",
      "   [0.64314 ]]\n",
      "\n",
      "  [[0.023529]\n",
      "   [0.027451]\n",
      "   [0.027451]\n",
      "   ...\n",
      "   [0.63529 ]\n",
      "   [0.63529 ]\n",
      "   [0.63137 ]]\n",
      "\n",
      "  [[0.035294]\n",
      "   [0.054902]\n",
      "   [0.086275]\n",
      "   ...\n",
      "   [0.50196 ]\n",
      "   [0.4902  ]\n",
      "   [0.48627 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.078431]\n",
      "   [0.11373 ]\n",
      "   [0.14118 ]\n",
      "   ...\n",
      "   [0.38039 ]\n",
      "   [0.48235 ]\n",
      "   [0.88627 ]]\n",
      "\n",
      "  [[0.027451]\n",
      "   [0.035294]\n",
      "   [0.05098 ]\n",
      "   ...\n",
      "   [0.37255 ]\n",
      "   [0.4549  ]\n",
      "   [0.86667 ]]\n",
      "\n",
      "  [[0.019608]\n",
      "   [0.023529]\n",
      "   [0.023529]\n",
      "   ...\n",
      "   [0.38039 ]\n",
      "   [0.44314 ]\n",
      "   [0.82353 ]]]\n",
      "\n",
      "\n",
      " [[[0.027451]\n",
      "   [0.023529]\n",
      "   [0.027451]\n",
      "   ...\n",
      "   [0.64706 ]\n",
      "   [0.63529 ]\n",
      "   [0.63922 ]]\n",
      "\n",
      "  [[0.027451]\n",
      "   [0.023529]\n",
      "   [0.031373]\n",
      "   ...\n",
      "   [0.53725 ]\n",
      "   [0.51373 ]\n",
      "   [0.50196 ]]\n",
      "\n",
      "  [[0.031373]\n",
      "   [0.05098 ]\n",
      "   [0.082353]\n",
      "   ...\n",
      "   [0.53333 ]\n",
      "   [0.54902 ]\n",
      "   [0.56471 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.090196]\n",
      "   [0.11765 ]\n",
      "   [0.1451  ]\n",
      "   ...\n",
      "   [0.38039 ]\n",
      "   [0.37647 ]\n",
      "   [0.37647 ]]\n",
      "\n",
      "  [[0.031373]\n",
      "   [0.039216]\n",
      "   [0.054902]\n",
      "   ...\n",
      "   [0.38039 ]\n",
      "   [0.38039 ]\n",
      "   [0.37255 ]]\n",
      "\n",
      "  [[0.027451]\n",
      "   [0.023529]\n",
      "   [0.023529]\n",
      "   ...\n",
      "   [0.36863 ]\n",
      "   [0.38039 ]\n",
      "   [0.37647 ]]]\n",
      "\n",
      "\n",
      " [[[0.023529]\n",
      "   [0.027451]\n",
      "   [0.023529]\n",
      "   ...\n",
      "   [0.67451 ]\n",
      "   [0.66667 ]\n",
      "   [0.6549  ]]\n",
      "\n",
      "  [[0.027451]\n",
      "   [0.027451]\n",
      "   [0.027451]\n",
      "   ...\n",
      "   [0.64314 ]\n",
      "   [0.64314 ]\n",
      "   [0.64314 ]]\n",
      "\n",
      "  [[0.035294]\n",
      "   [0.058824]\n",
      "   [0.086275]\n",
      "   ...\n",
      "   [0.54118 ]\n",
      "   [0.52941 ]\n",
      "   [0.52549 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.07451 ]\n",
      "   [0.10588 ]\n",
      "   [0.13725 ]\n",
      "   ...\n",
      "   [0.38039 ]\n",
      "   [0.37647 ]\n",
      "   [0.4     ]]\n",
      "\n",
      "  [[0.031373]\n",
      "   [0.035294]\n",
      "   [0.047059]\n",
      "   ...\n",
      "   [0.37647 ]\n",
      "   [0.37647 ]\n",
      "   [0.39216 ]]\n",
      "\n",
      "  [[0.027451]\n",
      "   [0.023529]\n",
      "   [0.023529]\n",
      "   ...\n",
      "   [0.37647 ]\n",
      "   [0.37255 ]\n",
      "   [0.38431 ]]]]\n",
      "(20798, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "print(PIE_Xtrain)\n",
    "print(PIE_Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 69)                159045    \n",
      "=================================================================\n",
      "Total params: 177,861\n",
      "Trainable params: 177,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "325/325 [==============================] - 11s 32ms/step - loss: 3.6444 - accuracy: 0.1527 - val_loss: 2.0473 - val_accuracy: 0.5048\n",
      "Epoch 2/10\n",
      "325/325 [==============================] - 10s 32ms/step - loss: 0.6153 - accuracy: 0.8388 - val_loss: 1.2612 - val_accuracy: 0.6987\n",
      "Epoch 3/10\n",
      "325/325 [==============================] - 11s 34ms/step - loss: 0.2674 - accuracy: 0.9327 - val_loss: 0.8885 - val_accuracy: 0.7887\n",
      "Epoch 4/10\n",
      "325/325 [==============================] - 14s 42ms/step - loss: 0.1844 - accuracy: 0.9531 - val_loss: 0.7017 - val_accuracy: 0.8234\n",
      "Epoch 5/10\n",
      "325/325 [==============================] - 14s 42ms/step - loss: 0.1421 - accuracy: 0.9615 - val_loss: 0.4979 - val_accuracy: 0.8823\n",
      "Epoch 6/10\n",
      "325/325 [==============================] - 13s 41ms/step - loss: 0.1050 - accuracy: 0.9702 - val_loss: 0.3943 - val_accuracy: 0.8987\n",
      "Epoch 7/10\n",
      "325/325 [==============================] - 13s 41ms/step - loss: 0.0905 - accuracy: 0.9762 - val_loss: 0.2908 - val_accuracy: 0.9255\n",
      "Epoch 8/10\n",
      "325/325 [==============================] - 14s 42ms/step - loss: 0.0724 - accuracy: 0.9815 - val_loss: 0.2240 - val_accuracy: 0.9437\n",
      "Epoch 9/10\n",
      "325/325 [==============================] - 14s 42ms/step - loss: 0.0622 - accuracy: 0.9815 - val_loss: 0.1766 - val_accuracy: 0.9532\n",
      "Epoch 10/10\n",
      "325/325 [==============================] - 13s 42ms/step - loss: 0.0595 - accuracy: 0.9833 - val_loss: 0.1273 - val_accuracy: 0.9749\n",
      "0.9748043328859407\n",
      "0.9872693701692399\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model definition and building\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape = (32, 32, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(69, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(PIE_Xtrain, PIE_ytrain, batch_size=64, epochs=10, validation_data=(PIE_Xtest,PIE_ytest))\n",
    "\n",
    "y_hat = np.argmax(model.predict(PIE_Xtest), axis=-1)\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"): # Method from https://medium.com/@plog397/auc-roc-curve-scoring-function-for-multi-class-classification-9822871a6659\n",
    "  lb = LabelBinarizer()\n",
    "  lb.fit(y_test)\n",
    "  y_test = lb.transform(y_test)\n",
    "  y_pred = lb.transform(y_pred)\n",
    "  return roc_auc_score(y_test, y_pred, average=average)\n",
    "def multiclass_f_score(y_test, y_pred, average=\"macro\"): # Method from https://medium.com/@plog397/auc-roc-curve-scoring-function-for-multi-class-classification-9822871a6659\n",
    "  lb = LabelBinarizer()\n",
    "  lb.fit(y_test)\n",
    "  y_test = lb.transform(y_test)\n",
    "  y_pred = lb.transform(y_pred)\n",
    "  return f1_score(y_test, y_pred, average=average)\n",
    "\n",
    "print(multiclass_f_score(PIE_ytest,y_hat))\n",
    "print(multiclass_roc_auc_score(PIE_ytest,y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def td_create_model(filter_num=0, ker_size=0, dropout_r=0.0,dense=0):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape = (32, 32, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(69, activation=\"softmax\"))\n",
    "      \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=td_create_model, epochs=100, batch_size = 10, verbose=0)\n",
    "\n",
    "filter_num = [8, 16,32]\n",
    "ker_size    = [2, 4, 6]\n",
    "dropout_r  = [0.5,0.6,0.7]\n",
    "dense      = [20,60,120]\n",
    "\n",
    "\n",
    "param_grid = dict(filter_num=filter_num, ker_size=ker_size, dropout_r=dropout_r, dense=dense)\n",
    "\n",
    "cv_method = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv_method, scoring='accuracy',verbose=10)\n",
    "grid.fit(X,y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
